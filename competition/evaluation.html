<h1 style="color: grey;">Data, Models and Evaluation</h1>
<h2>Data<strong><br /></strong></h2>
<p>Since the scenario proposed by SemEval-2021 Task 10 is domain adaptation with no access to the source data, no annotated training set is distributed. Instead, participants are provided with models trained on that source data, the development data representing a new domain on which participants can explore domain adaptation algorithms, and the test data representing another new domain on which the participant's approaches will be evaluated.</p>
<p>The <strong>negation detection</strong> track uses as development data the i2b2 2010 Challenge Dataset, a de-identified dataset of notes from Partners HealthCare, containing 2886 unlabeled train instances (entities in sentence context), and 5545 dev instances with a corresponding labeling for with negation status. The original i2b2 data set had multi-label annotations in the set Asserted, Negated, Uncertain, Hypothetical, Conditional, FamilyRelated - to align with other challenge datasets we have kept the Negated category but mapped all other categories to "Not negated." The i2b2 2010 Challenge data requires a Data Use Agreement with Partners HealthCare, in order to access the development data, participants must first obtain access through the <a href="https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/" target="_blank">n2c2/DBMI Data Portal</a>. After downloading the 2010 data, participants can then run scripts that are in the Github repo for this task.</p>
<p>For <strong>time expression recognition</strong>, the development data is the annotated news portion of the SemEval 2018 Task 6 data. The source text is from the freely available <a href="https://www.cs.york.ac.uk/semeval-2013/task1/index.php%3Fid=data.html" target="_blank">TimeBank</a>, and the 2,000+ time entity annotations are stored in <a href="https://github.com/weitechen/anafora">Anafora</a> XML format.</p>
<p>Participants should also <a href="https://mimic.physionet.org/" target="_blank">obtain access to the MIMIC III corpus</a>, as a portion of it may be used for one or both of the test sets. Access to the MIMIC data requires participants to complete a CITI "Data or Specimens Only Research" online course, and then make an online request through PhysioNet. The course takes only a couple of hours online, and access requests are typically approved within a few days.</p>

<h2>Models<strong><br /></strong></h2>
<p>Paricipants are provided with trained models for both negation detection and time expression recognition. In both cases, we have used the <em>RoBERTa-base</em> (Liu et al., 2019) pretrained model included in the <a href="https://github.com/huggingface/transformers" target="_blank">Huggingface Transformers</a> library:</p>
<ul>
  <li>For <strong>negation detection</strong>, we provide a "span-in-context" classification model, fine-tuned on the 10,259 instances (902 negated) in the SHARP Seed dataset of de-identified clinical notes from Mayo Clinic, which the organizers have access to but cannot currently be distributed (models are approved to be distributed). In the SHARP data, clinical events are marked with a boolean polarity indicator, with values of either <em>asserted </em>or <em>negated</em>.</li>
  <li>For <strong>time expression recognition</strong>, we provide a sequence tagging model, fine-tuned on the 25,000+ time expressions in the de-identified clinical notes from the Mayo Clinic in SemEval 2018 Task 6, which are available to the task organizers, but are difficult to gain access to due to the complex data use agreements necessary (models are approved to be distributed).</li>
</ul>
<h2>Evaluation metrics</h2>
<p>The scores for each track are calculated as follows:</p>
<ul>
  <li><strong>Negation detection</strong> will be evaluated using the standard precision, recall and F<sub>1</sub> scores as used in most published work -- recall points are gained by correctly predicting that a negated entity is negated, precision points are obtained if a predicted negation is correct.</li>
  <li><strong>Time expression recognition</strong> will be evaluated using the standard precision, recall and F<sub>1</sub> previously used for the entity-finding portion of SemEval 2018 Task 6.</li>
</ul>
<h2>System Output Format</h2>
<p>For the <strong>negation detection</strong> track, the output format is one classifier output per line, where the lines correspond to the lines in the input. A prediction of "Negated" should be output as 1, while a prediction of "Not negated" should be output as -1.</p>
<p>For <strong>time expression recognition</strong>, your system must produce <a href="https://github.com/weitechen/anafora" target="_blank">Anafora XML format</a> files in Anafora's standard directory organization.</p>
<p style="text-align: left;">Make sure that you comply with following rules when you create &nbsp;your output directory:</p>
<ul>
<li>The root must contain only the track directories, <code>negation</code> and <code>time</code>. If you are not participating in one of the tracks, do not include its directory.</li>
<li>In the <code>negation</code> directory, include a single tsv file with the name <code>system.tsv</code>.</li>
<li>The <code>time</code> directory, follow the same structure and names as in the dataset:</li>
<ul>
<li>Each top-level directory must contain only document directories, named exactly as in the input dataset.</li>
<li>Each document directory must contain only the corresponding annotation file.</li>
<li>The name of each annotation file must match the document name and have a <code>.TimeNorm.system.completed.xml</code> extension.</li>
</ul>
</ul>
<p>For example, for the development data, your directory structure should look like:</p>
<table style="border-color: #e6ecff; background-color: #eaeaea; border-width: 0px; height: 200px; width: 500px;" border="0" align="center">
<tbody>
  <tr>
    <td>
      <ul>
        <li>negation</li>
        <ul>
          <li>system.tsv</li>
        </ul>
        <li>time</li>
        <ul>
          <li>AQUAINT</li>
          <ul>
            <li>APW19980807.0261</li>
            <ul>
              <li>APW19980807.0261.TimeNorm.system.completed.xml</li>
            </ul>
            <li>APW19980808.0022</li>
            <ul>
              <li>APW19980808.0022.TimeNorm.system.completed.xml</li>
            </ul>
            <li>...</li>
          </ul>
        </ul>
        <ul>
          <li>TimeBank</li>
          <ul>
            <li>ABC19980108.1830.0711</li>
            <ul>
              <li>ABC19980108.1830.0711.TimeNorm.system.completed.xml</li>
            </ul>
            <li>ABC19980114.1830.0611</li>
            <ul>
              <li>ABC19980114.1830.0611.TimeNorm.system.completed.xml</li>
            </ul>
            <li>...</li>
          </ul>
        </ul>
      </ul>
    </td>
  </tr>
</tbody>
</table>
<h2>References</h2>
<p>Liu Y., Ott M., Goyal N., Du J., Joshi M., Chen D., Levy O., Lewis M., Zettlemoyer L., and Stoyanov V. <a href="https://arxiv.org/pdf/1907.11692.pdf" target="_blank">Roberta: A robustly optimized bert pretraining approach</a>. arXiv preprint. 2019.</p>
<p>&nbsp;</p>
